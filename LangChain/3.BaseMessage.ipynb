{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 聊天消息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 安装依赖包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用SystemMessage和HumanMessage进行一轮对话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='你好！很高兴见到你！有什么我可以帮忙的吗？' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 17, 'total_tokens': 28, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'deepseek-v3', 'system_fingerprint': None, 'id': 'chatcmpl-0fd6c8ee-68d5-9c2d-9542-e41246d22339', 'finish_reason': 'stop', 'logprobs': None} id='run-22847858-2fc6-4c92-ba74-095012768962-0' usage_metadata={'input_tokens': 17, 'output_tokens': 11, 'total_tokens': 28, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage,SystemMessage,AIMessage \n",
    "\n",
    "# 读取配置文件\n",
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "    api_key = config[\"api_key\"]\n",
    "\n",
    "# 设置环境变量\n",
    "os.environ[\"OPENAI_API_KEY\"] = config[\"api_key\"]\n",
    "os.environ[\"OPENAI_API_BASE\"] = config[\"api_base\"]\n",
    "\n",
    "# 创建 OpenAI 客户端\n",
    "llm = ChatOpenAI(model=\"deepseek-v3\",temperature=0.7)\n",
    "\n",
    "# 简单对话\n",
    "r = llm.invoke(\n",
    "    [\n",
    "    SystemMessage(content=\"你是一个AI助手，请回答用户的问题。\"),\n",
    "    HumanMessage(content=\"你好，世界！\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加入AIMessage模拟进行两轮对话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='苹果是一种非常多功能的水果，可以用来制作各种菜肴。以下是一些可以用苹果烹饪的菜肴：\\n\\n1. **苹果派**：经典的甜点，用苹果片、糖、肉桂和黄油填充在酥皮中烘烤而成。\\n\\n2. **苹果酱**：将苹果去皮去核，切块后加糖和水煮至软烂，可以做成甜美的苹果酱，适合搭配面包或作为甜点的配料。\\n\\n3. **烤苹果**：将苹果核挖出，填入糖、肉桂、坚果等，然后烤至软糯，是一道简单的甜点。\\n\\n4. **苹果沙拉**：将苹果切片或切块，与其他水果、蔬菜、坚果和奶酪混合，加入沙拉酱，制作成清爽的沙拉。\\n\\n5. **苹果炖猪肉**：将苹果与猪肉一起炖煮，苹果的甜味可以中和猪肉的油腻，增添风味。\\n\\n6. **苹果醋**：将苹果发酵制成醋，可以用来调味或制作沙拉酱。\\n\\n7. **苹果蛋糕**：将苹果切块或切片，加入蛋糕面糊中烘烤，制作成湿润香甜的苹果蛋糕。\\n\\n8. **苹果汤**：将苹果与洋葱、土豆等蔬菜一起煮成汤，可以加入奶油或椰奶增加口感。\\n\\n9. **苹果煎饼**：将苹果切丝或切块，加入煎饼面糊中，煎至金黄，制作成美味的苹果煎饼。\\n\\n10. **苹果咖喱**：将苹果切块加入咖喱中，增添一丝甜味和果香，适合搭配鸡肉或蔬菜。\\n\\n这些菜肴展示了苹果在甜点和主菜中的多样性，您可以根据自己的口味和喜好选择适合的食谱。' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 354, 'prompt_tokens': 28, 'total_tokens': 382, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'deepseek-v3', 'system_fingerprint': None, 'id': 'chatcmpl-1470a3e0-9795-9dd7-a42e-6e2e5e690469', 'finish_reason': 'stop', 'logprobs': None} id='run-a9b0e142-73ad-40dd-a060-febc57d99779-0' usage_metadata={'input_tokens': 28, 'output_tokens': 354, 'total_tokens': 382, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage,SystemMessage,AIMessage \n",
    "\n",
    "# 读取配置文件\n",
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "    api_key = config[\"api_key\"]\n",
    "\n",
    "# 设置环境变量\n",
    "os.environ[\"OPENAI_API_KEY\"] = config[\"api_key\"]\n",
    "os.environ[\"OPENAI_API_BASE\"] = config[\"api_base\"]\n",
    "\n",
    "# 创建 OpenAI 客户端\n",
    "llm = ChatOpenAI(model=\"deepseek-v3\",temperature=0.7)\n",
    "\n",
    "# 简单对话\n",
    "r = llm.invoke(\n",
    "    [\n",
    "    SystemMessage(content=\"你是一个AI助手，请回答用户的问题。\"),\n",
    "    HumanMessage(content=\"我喜欢吃什么？\"),\n",
    "    AIMessage(content=\"我喜欢吃苹果。\"),\n",
    "    HumanMessage(content=\"苹果可以煮什么菜\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文档——数据结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='你好，世界！' metadata={'source': 'test'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "doc = Document(page_content=\"你好，世界！\",metadata={\"source\":\"test\"})\n",
    "\n",
    "print(doc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Anaconda)",
   "language": "python",
   "name": "anaconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
