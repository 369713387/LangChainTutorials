{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cachingç¼“å­˜\n",
    "LangChainä¸ºLLMsæä¾›äº†å¯é€‰çš„ç¼“å­˜å±‚ã€‚è¿™å¾ˆæœ‰ç”¨,åŸå› æœ‰ä¸¤ä¸ª:\n",
    "- å¦‚æœç»å¸¸å¤šæ¬¡è¯·æ±‚ç›¸åŒçš„å®Œæˆ,å®ƒå¯ä»¥å‡å°‘æ‚¨å¯¹LLMæä¾›ç¨‹åºè¿›è¡Œçš„APIè°ƒç”¨æ¬¡æ•°æ¥èŠ‚çœèµ„é‡‘ã€‚\n",
    "- å®ƒå¯ä»¥é€šè¿‡å‡å°‘æ‚¨å¯¹LLMæä¾›ç¨‹åºè¿›è¡Œçš„APIè°ƒç”¨æ¬¡æ•°æ¥åŠ é€Ÿæ‚¨çš„åº”ç”¨ç¨‹åº"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## é€šè¿‡å­˜å‚¨åˆ°æ•°æ®åº“æ¥å®ç°ç¼“å­˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ¨ã€æ—ºä»”ç‰›å¥¶ã€‘å¥¶é¦™æµ“éƒï¼Œå¿«ä¹åŠ å€ï¼âœ¨\n",
      "\n",
      "å§å¦¹ä»¬ï¼Œä»Šå¤©å¿…é¡»ç»™å¤§å®¶å®‰åˆ©ä¸€æ¬¾å®è—é¥®å“â€”â€”**æ—ºä»”ç‰›å¥¶**ï¼æ— è®ºæ˜¯ç«¥å¹´å›å¿†è¿˜æ˜¯æ—¥å¸¸å¿…å¤‡ï¼Œå®ƒéƒ½å æ®ç€æˆ‘ä»¬å¿ƒä¸­ä¸å¯æ›¿ä»£çš„ä½ç½®ï¼ğŸ¥›\n",
      "\n",
      "ğŸ’¡ **ä¸ºä»€ä¹ˆé€‰æ‹©æ—ºä»”ç‰›å¥¶ï¼Ÿ**  \n",
      "1ï¸âƒ£ **ç»å…¸å¥½å–**ï¼šé†‡åšçš„å¥¶é¦™ï¼Œç”œè€Œä¸è…»ï¼Œä¸€å£ä¸‹å»ä»¿ä½›å›åˆ°äº†æ— å¿§æ— è™‘çš„å°æ—¶å€™ï¼  \n",
      "2ï¸âƒ£ **è¥å…»æ»¡åˆ†**ï¼šå¯Œå«è›‹ç™½è´¨å’Œé’™è´¨ï¼Œå–å‡ºå¥åº·å¥½çŠ¶æ€ï¼Œç®€ç›´æ˜¯å­¦ç”Ÿå…šå’Œä¸Šç­æ—çš„å®Œç¾æ­æ¡£ï¼  \n",
      "3ï¸âƒ£ **é¢œå€¼æ‹…å½“**ï¼šç»å…¸çº¢è“é…è‰²+å‘†èŒæ—ºä»”å¤´åƒï¼Œæ‹ç…§æ‰“å¡ç»å¯¹å¸ç›ï¼éšæ‰‹ä¸€æ‹å°±æ˜¯æœ‹å‹åœˆç‚¹èµåˆ©å™¨ï¼ğŸ“¸  \n",
      "\n",
      "ğŸŒŸ **è¶…å¤šåˆ›æ„å–æ³•**  \n",
      "- å†·çƒ­çš†å®œï¼šå†¬å¤©çƒ­é¥®æš–èƒƒï¼Œå¤å¤©å†°é•‡æ¸…çˆ½ï¼  \n",
      "- åˆ›æ„è°ƒé…’ï¼šåŠ å…¥å’–å•¡æˆ–å¥¶èŒ¶ä¸­ï¼Œè§£é”æ–°å£å‘³ï¼  \n",
      "- çƒ˜ç„™ä¼´ä¾£ï¼šåšè›‹ç³•ã€å¸ƒä¸ï¼Œè®©ç”œç‚¹æ›´é¦™æµ“ï¼  \n",
      "\n",
      "ğŸ **ç¦åˆ©æ—¶é—´**  \n",
      "å¿«å»è¶…å¸‚å›¤å‡ ç®±å§ï¼ç°åœ¨è¿˜æœ‰è¶…å€¼ä¼˜æƒ å“¦ï½å’Œé—ºèœœä¸€èµ·åˆ†äº«è¿™ä»½å¿«ä¹ï¼Œå¹¸ç¦æ„Ÿç¬é—´æ‹‰æ»¡ï¼ğŸ’–\n",
      "\n",
      "#æ—ºä»”ç‰›å¥¶ #ç«¥å¹´å›å¿† #å¥åº·å¥½ç‰© #ç½‘çº¢é¥®å“\n",
      "CPU times: total: 78.1 ms\n",
      "Wall time: 58 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# ç»Ÿè®¡ä»£ç æ—¶é—´\n",
    "import os\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain.cache import SQLiteCache\n",
    "\n",
    "# è·å–å½“å‰æ–‡ä»¶çš„ç»å¯¹è·¯å¾„\n",
    "db_path = os.path.abspath(\"/langchain_cache.db\")\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ªSQLiteCacheå¯¹è±¡\n",
    "cache = SQLiteCache(\n",
    "    database_path=db_path\n",
    ")   \n",
    "\n",
    "# è®¾ç½®ç¼“å­˜\n",
    "set_llm_cache(cache)\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    è¯·æ ¹æ®ä¸‹é¢çš„ä¸»é¢˜å†™ä¸€ç¯‡å°çº¢ä¹¦è¥é”€çš„çŸ­æ–‡ï¼š{input}\n",
    "    \"\"\",\n",
    "    input_variables=[\"input\"]\n",
    ")\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "# åˆ›å»ºä¸€ä¸ªLLMå¯¹è±¡\n",
    "llm = ChatOpenAI(\n",
    "    model= \"qwen-turbo\",\n",
    "    api_key=os.getenv(\"API_KEY\"),\n",
    "    base_url=os.getenv(\"API_BASEURL\")\n",
    ")\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ªChain\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# æ‰§è¡ŒChain\n",
    "result = chain.invoke(\"æ—ºä»”ç‰›å¥¶\")\n",
    "\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Anaconda)",
   "language": "python",
   "name": "anaconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
