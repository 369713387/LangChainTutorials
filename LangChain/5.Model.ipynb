{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 聊天模型\n",
    "接收一系列消息并返回消息输出的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='作为一个AI，我无法直接了解你的个人喜好。不过，你可以告诉我你平时喜欢吃什么类型的食物，我可以根据你的口味推荐一些美食或食谱！比如，你喜欢甜食、辣味、还是清淡的食物？' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 16, 'total_tokens': 61, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'deepseek-v3', 'system_fingerprint': None, 'id': 'chatcmpl-e51feae6-884f-96f4-91fe-90bf83a8a461', 'finish_reason': 'stop', 'logprobs': None} id='run-b4491ef1-ee34-4d1e-ac4b-e57e93e1d7e3-0' usage_metadata={'input_tokens': 16, 'output_tokens': 45, 'total_tokens': 61, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage,SystemMessage,AIMessage \n",
    "\n",
    "# 读取配置文件\n",
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "    api_key = config[\"api_key\"]\n",
    "\n",
    "# 设置环境变量\n",
    "os.environ[\"OPENAI_API_KEY\"] = config[\"api_key\"]\n",
    "os.environ[\"OPENAI_API_BASE\"] = config[\"api_base\"]\n",
    "\n",
    "# 创建 OpenAI 客户端\n",
    "llm = ChatOpenAI(model=\"deepseek-v3\")\n",
    "\n",
    "# 调用聊天模型\n",
    "r = llm.invoke(\n",
    "    [\n",
    "    SystemMessage(content=\"你是一个AI助手，请回答用户的问题。\"),\n",
    "    HumanMessage(content=\"我喜欢吃什么？\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 函数调用模型\n",
    "可以提供结构化的数据输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "用户: 深圳今天天气怎么样？\n",
      "助手: 查询出错: Error code: 400 - {'error': {'code': 'invalid_parameter_error', 'param': None, 'message': '<400> InternalError.Algo.InvalidParameter: The tool call is not supported.', 'type': 'invalid_request_error'}, 'id': 'chatcmpl-eee32a5d-16f1-956e-9bdd-22ca986fccc0', 'request_id': 'eee32a5d-16f1-956e-9bdd-22ca986fccc0'}\n",
      "\n",
      "用户: 我需要带伞吗？\n",
      "助手: 查询出错: Error code: 400 - {'error': {'code': 'invalid_parameter_error', 'param': None, 'message': '<400> InternalError.Algo.InvalidParameter: The tool call is not supported.', 'type': 'invalid_request_error'}, 'id': 'chatcmpl-b30398e5-6e08-9f60-abe6-278caa1d84d4', 'request_id': 'b30398e5-6e08-9f60-abe6-278caa1d84d4'}\n",
      "\n",
      "用户: 现在温度多少度？\n",
      "助手: 查询出错: Error code: 400 - {'error': {'code': 'invalid_parameter_error', 'param': None, 'message': '<400> InternalError.Algo.InvalidParameter: The tool call is not supported.', 'type': 'invalid_request_error'}, 'id': 'chatcmpl-fdf34e76-9ee8-9ff6-91cb-2ab26e5eba61', 'request_id': 'fdf34e76-9ee8-9ff6-91cb-2ab26e5eba61'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# 读取配置文件\n",
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "    api_key = config[\"api_key\"]\n",
    "\n",
    "# 设置环境变量\n",
    "os.environ[\"OPENAI_API_KEY\"] = config[\"api_key\"]\n",
    "os.environ[\"OPENAI_API_BASE\"] = config[\"api_base\"]\n",
    "\n",
    "# 创建 OpenAI 客户端\n",
    "llm = ChatOpenAI(model= config[\"deepseek_model\"])\n",
    "\n",
    "class WeatherTool(BaseModel):\n",
    "    \"\"\"天气查询工具\"\"\"\n",
    "    \n",
    "    city: str = Field(description=\"城市名称\")\n",
    "    info_type: str = Field(\n",
    "        default=\"all\",\n",
    "        description=\"查询信息类型 (temperature/condition/all)\"\n",
    "    )\n",
    "\n",
    "def get_weather_info(city: str, info_type: str = \"all\") -> dict:\n",
    "    \"\"\"模拟天气 API 调用\"\"\"\n",
    "    weather_data = {\n",
    "        \"深圳\": {\n",
    "            \"temperature\": 25,\n",
    "            \"condition\": \"晴朗\",\n",
    "            \"humidity\": 65\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if city not in weather_data:\n",
    "        return {\"error\": f\"未找到 {city} 的天气信息\"}\n",
    "        \n",
    "    data = weather_data[city]\n",
    "    if info_type == \"temperature\":\n",
    "        return {\"temperature\": data[\"temperature\"]}\n",
    "    elif info_type == \"condition\":\n",
    "        return {\"condition\": data[\"condition\"]}\n",
    "    return data\n",
    "\n",
    "class WeatherAssistant:\n",
    "    def __init__(self, api_key: str,openai_api_base:str,model_name:str):\n",
    "        self.llm = ChatOpenAI(\n",
    "            openai_api_key=api_key,\n",
    "            openai_api_base=openai_api_base,\n",
    "            model_name=model_name\n",
    "        )\n",
    "        \n",
    "        # 绑定工具\n",
    "        self.llm_with_tools = self.llm.bind_tools(\n",
    "            tools=[WeatherTool],\n",
    "            tool_choice=\"auto\",\n",
    "            strict=True\n",
    "        )\n",
    "        \n",
    "    def query_weather(self, user_input: str):\n",
    "        try:\n",
    "            # 系统提示\n",
    "            messages = [\n",
    "                SystemMessage(content=\"你是一个专业的天气助手，可以帮助用户查询天气信息。\"),\n",
    "                HumanMessage(content=user_input)\n",
    "            ]\n",
    "            \n",
    "            # 调用模型\n",
    "            response = self.llm_with_tools.invoke(messages)\n",
    "            \n",
    "            # 处理工具调用\n",
    "            if hasattr(response, 'tool_calls') and response.tool_calls:\n",
    "                results = []\n",
    "                for tool_call in response.tool_calls:\n",
    "                    args = json.loads(tool_call['args'])\n",
    "                    weather_info = get_weather_info(**args)\n",
    "                    results.append(weather_info)\n",
    "                \n",
    "                # 让模型解释结果\n",
    "                messages.append(response)\n",
    "                messages.append(\n",
    "                    SystemMessage(content=f\"天气数据: {json.dumps(results, ensure_ascii=False)}\")\n",
    "                )\n",
    "                final_response = self.llm.invoke(messages)\n",
    "                return final_response.content\n",
    "                \n",
    "            return response.content\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"查询出错: {str(e)}\"\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    assistant = WeatherAssistant(config[\"api_key\"],config[\"api_base\"],config[\"deepseek_model\"])\n",
    "    \n",
    "    # 测试查询\n",
    "    queries = [\n",
    "        \"深圳今天天气怎么样？\",\n",
    "        \"我需要带伞吗？\",\n",
    "        \"现在温度多少度？\"\n",
    "    ]\n",
    "    \n",
    "    for query in queries:\n",
    "        print(f\"\\n用户: {query}\")\n",
    "        response = assistant.query_weather(query)\n",
    "        print(f\"助手: {response}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文本嵌入模型\n",
    "将文本转换为向量（一系列包含文本语义含义的数字）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文本：我是一个特种兵，我正在执行任务\n",
      "向量前5个维度：[0.005827370179008478, 0.019640165448568597, 0.005647014004844929, -0.028533590588357416, 0.034081097738491425]\n",
      "向量维度：1536\n",
      "\n",
      "多个文本的嵌入向量：\n",
      "\n",
      "文本 1：我是一个特种兵，我正在执行任务\n",
      "向量前5个维度：[0.005827370179008478, 0.019640165448568597, 0.005647014004844929, -0.028533590588357416, 0.034081097738491425]\n",
      "向量维度：1536\n",
      "\n",
      "文本 2：今天天气真好，适合出去玩\n",
      "向量前5个维度：[-0.0017264320383616743, -0.023259233422935226, 0.059993727743405785, -0.02754057904414808, -0.03161609074126417]\n",
      "向量维度：1536\n",
      "\n",
      "文本 3：人工智能正在改变世界\n",
      "向量前5个维度：[0.02374165535780939, -0.033151145116250044, -0.03279220000284904, -0.013242510790829968, 0.06194367099834502]\n",
      "向量维度：1536\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import dashscope\n",
    "from dashscope import TextEmbedding\n",
    "import numpy as np\n",
    "\n",
    "# 读取配置文件\n",
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "    api_key = config[\"api_key\"]\n",
    "\n",
    "# 设置环境变量\n",
    "os.environ[\"DASHSCOPE_API_KEY\"] = config[\"api_key\"]\n",
    "\n",
    "class DashScopeEmbeddings:\n",
    "    def __init__(self, api_key: str = None):\n",
    "        \"\"\"初始化 DashScope Embeddings\"\"\"\n",
    "        self.api_key = api_key or os.getenv('DASHSCOPE_API_KEY')\n",
    "        dashscope.api_key = self.api_key\n",
    "\n",
    "    def embed_query(self, text: str) -> list:\n",
    "        \"\"\"获取单个文本的嵌入向量\"\"\"\n",
    "        try:\n",
    "            response = TextEmbedding.call(\n",
    "                model='text-embedding-v2',  # 使用 text-embedding-v2 模型\n",
    "                input=text\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                # 返回嵌入向量\n",
    "                return response.output['embeddings'][0]\n",
    "            else:\n",
    "                raise Exception(f\"API调用失败: {response.code} - {response.message}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            raise Exception(f\"生成嵌入向量时出错: {str(e)}\")\n",
    "\n",
    "    def embed_documents(self, texts: list) -> list:\n",
    "        \"\"\"获取多个文本的嵌入向量\"\"\"\n",
    "        try:\n",
    "            response = TextEmbedding.call(\n",
    "                model='text-embedding-v2',\n",
    "                input=texts\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                # 返回嵌入向量列表\n",
    "                return response.output['embeddings']\n",
    "            else:\n",
    "                raise Exception(f\"API调用失败: {response.code} - {response.message}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            raise Exception(f\"生成嵌入向量时出错: {str(e)}\")\n",
    "\n",
    "# 使用示例\n",
    "def main():\n",
    "    # 创建 embeddings 实例\n",
    "    embeddings_model = DashScopeEmbeddings(api_key=config[\"api_key\"])\n",
    "\n",
    "    # 测试单个文本\n",
    "    try:\n",
    "        text = \"我是一个特种兵，我正在执行任务\"\n",
    "        embedding = embeddings_model.embed_query(text)\n",
    "        \n",
    "        print(f\"文本：{text}\")\n",
    "        print(f\"向量前5个维度：{embedding[\"embedding\"][:5]}\")\n",
    "        print(f\"向量维度：{len(embedding[\"embedding\"])}\")\n",
    "        \n",
    "        # 测试多个文本\n",
    "        texts = [\n",
    "            \"我是一个特种兵，我正在执行任务\",\n",
    "            \"今天天气真好，适合出去玩\",\n",
    "            \"人工智能正在改变世界\"\n",
    "        ]\n",
    "        \n",
    "        embeddings = embeddings_model.embed_documents(texts)\n",
    "        print(\"\\n多个文本的嵌入向量：\")\n",
    "        for i, (text, emb) in enumerate(zip(texts, embeddings)):\n",
    "            print(f\"\\n文本 {i+1}：{text}\")\n",
    "            print(f\"向量前5个维度：{emb[\"embedding\"][:5]}\")\n",
    "            print(f\"向量维度：{len(emb[\"embedding\"])}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"错误：{str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Anaconda)",
   "language": "python",
   "name": "anaconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
