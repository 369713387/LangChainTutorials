{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 输出解析器\n",
    "\n",
    "输出解析器是 LangChain 中的一个重要组件，它主要用于将语言模型的输出转换为结构化数据。\n",
    "\n",
    "## 主要功能\n",
    "\n",
    "1. **格式化输出**：将语言模型的文本输出转换为特定的格式，如 JSON、Python 对象等\n",
    "2. **验证输出**：确保输出符合预期的格式和约束\n",
    "3. **错误处理**：当输出不符合预期时提供清晰的错误信息\n",
    "\n",
    "## 内置输出解析器\n",
    "\n",
    "LangChain 提供了多种内置的输出解析器：\n",
    "\n",
    "1. `PydanticOutputParser`：将输出解析为 Pydantic 模型\n",
    "2. `StructuredOutputParser`：将输出解析为结构化数据\n",
    "3. `CommaSeparatedListOutputParser`：将输出解析为逗号分隔的列表\n",
    "4. `OutputFixingParser`：自动修复格式错误的输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提示词：\n",
      "text='\\n    回答用户的询问并以JSON格式返回：\\n    The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"name\": {\"description\": \"用户名\", \"title\": \"Name\", \"type\": \"string\"}, \"age\": {\"description\": \"年龄\", \"title\": \"Age\", \"type\": \"integer\"}, \"height\": {\"description\": \"身高以厘米为单位\", \"title\": \"Height\", \"type\": \"integer\"}, \"weight\": {\"description\": \"体重以千克为单位\", \"title\": \"Weight\", \"type\": \"integer\"}}, \"required\": [\"name\", \"age\", \"height\", \"weight\"]}\\n```\\n    问题：阿里巴巴CEO\\n'\n",
      "name='张勇' age=51 height=176 weight=68\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import dashscope\n",
    "from dashscope import Generation\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 读取配置文件\n",
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# 与 Qwen 对话\n",
    "def chat_with_qwen(prompt_value):\n",
    "    # 从 StringPromptValue 中提取字符串\n",
    "    if hasattr(prompt_value, \"to_string\"):\n",
    "        prompt_str = prompt_value.to_string()\n",
    "    else:\n",
    "        prompt_str = str(prompt_value)\n",
    "    \n",
    "    response = Generation.call(\n",
    "        model=config['qwen_model'],\n",
    "        prompt=prompt_str,\n",
    "        api_key=config['api_key']\n",
    "    )\n",
    "    if response.status_code == 200:\n",
    "        return response.output.text\n",
    "    else:\n",
    "        raise Exception(f\"API调用失败: {response.code} - {response.message}\")\n",
    "\n",
    "# 创建一个调试回调函数\n",
    "def print_input(x):\n",
    "    print(f\"提示词：\\n{x}\")\n",
    "    return x\n",
    "\n",
    "# 定义一个 Pydantic 模型\n",
    "class User(BaseModel):\n",
    "    name: str = Field(description=\"用户名\")\n",
    "    age: int = Field(description=\"年龄\")\n",
    "    height: int = Field(description=\"身高以厘米为单位\")\n",
    "    weight: int = Field(description=\"体重以千克为单位\")\n",
    "\n",
    "# 创建一个输出解析器\n",
    "parser = PydanticOutputParser(pydantic_object=User)\n",
    "\n",
    "# 创建一个提示模板\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    回答用户的询问并以JSON格式返回：\n",
    "    {format_instructions}\n",
    "    问题：{question}\n",
    "\"\"\",\n",
    "input_variables=[\"question\"],\n",
    "partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "# 修改链，添加调试步骤\n",
    "debug_chain = (\n",
    "    {\"question\": RunnablePassthrough()} \n",
    "    | prompt\n",
    "    | print_input  # 这里会打印出格式化后的提示词\n",
    "    | chat_with_qwen \n",
    "    | StrOutputParser() \n",
    "    | parser\n",
    ")\n",
    "\n",
    "# 调用链\n",
    "result = debug_chain.invoke(\"阿里巴巴CEO\")\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  结构化提取\n",
    "## 使用LangChain的相应模式\n",
    "LangChain的相应模式将做两件事情：\n",
    "1. 使用真实格式说明，LangChain自动生成提示词\n",
    "2. 读取LLM的输出并将其转化为适合的Py对象"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从聊天消息中提取用户想要做的事情"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "结构化输出解析器的提示词:\n",
      " The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"菜品\": string  // 菜的名字\n",
      "\t\"地名\": string  // 该道菜品常见的地名\n",
      "}\n",
      "```\n",
      "最终的提示词：\n",
      " text='\\n    根据用户的输入，提取所有的菜品和地名\\n\\n    The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"菜品\": string  // 菜的名字\\n\\t\"地名\": string  // 该道菜品常见的地名\\n}\\n```\\n日记：探索美食与地名的奇妙之旅\\n日期：2025年4月9日\\n今天，我踏上了一段令人兴奋的美食之旅，探索了几个独特的地名及其特色美食。\\n早晨：杭州\\n清晨，我来到了美丽的杭州。这里的西湖美景令人陶醉，湖边的早茶更是不可错过。我点了一份龙井虾仁，鲜嫩的虾仁搭配着清香的龙井茶，味道鲜美，令人回味无穷。\\n中午：成都\\n午餐时，我飞往了成都，享受了正宗的四川火锅。火锅的麻辣味道让我感受到了一种前所未有的刺激，搭配新鲜的蔬菜和肉类，每一口都充满了满足感。成都的街头小吃也让我流连忘返，尤其是兔头，香辣可口，令人欲罢不能。\\n下午：广州\\n下午，我来到了广州，享受了一顿地道的早茶。点心如虾饺、烧卖、和蛋挞，每一样都精致可口。我特别喜欢那一口咬下去，皮薄馅嫩的虾饺，仿佛整个早晨的疲惫都被一扫而空。\\n晚上：上海\\n晚上，我抵达了上海，漫步在繁华的南京路。这里的美食琳琅满目，我选择了生煎包作为晚餐。外皮酥脆，内馅多汁，搭配醋和姜丝，味道绝妙。\\n总结\\n这一天的旅程让我更加热爱中国的美食文化。每一个地方都有其独特的风味和故事，真是一次难忘的体验！期待下一次的美食探索之旅。\\n\\n'\n",
      "=========结果===========\n",
      "```json\n",
      "[\n",
      "    {\n",
      "        \"菜品\": \"龙井虾仁\",\n",
      "        \"地名\": \"杭州\"\n",
      "    },\n",
      "    {\n",
      "        \"菜品\": \"四川火锅\",\n",
      "        \"地名\": \"成都\"\n",
      "    },\n",
      "    {\n",
      "        \"菜品\": \"兔头\",\n",
      "        \"地名\": \"成都\"\n",
      "    },\n",
      "    {\n",
      "        \"菜品\": \"虾饺\",\n",
      "        \"地名\": \"广州\"\n",
      "    },\n",
      "    {\n",
      "        \"菜品\": \"烧卖\",\n",
      "        \"地名\": \"广州\"\n",
      "    },\n",
      "    {\n",
      "        \"菜品\": \"蛋挞\",\n",
      "        \"地名\": \"广州\"\n",
      "    },\n",
      "    {\n",
      "        \"菜品\": \"生煎包\",\n",
      "        \"地名\": \"上海\"\n",
      "    }\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import dashscope\n",
    "from dashscope import Generation\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain.output_parsers import StructuredOutputParser,ResponseSchema\n",
    "\n",
    "# 读取配置文件\n",
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# 与 Qwen 对话\n",
    "def chat_with_qwen(prompt_value):\n",
    "    # 从 StringPromptValue 中提取字符串\n",
    "    if hasattr(prompt_value, \"to_string\"):\n",
    "        prompt_str = prompt_value.to_string()\n",
    "    else:\n",
    "        prompt_str = str(prompt_value)\n",
    "    \n",
    "    response = Generation.call(\n",
    "        model=config['qwen_model'],\n",
    "        prompt=prompt_str,\n",
    "        api_key=config['api_key']\n",
    "    )\n",
    "    if response.status_code == 200:\n",
    "        return response.output.text\n",
    "    else:\n",
    "        raise Exception(f\"API调用失败: {response.code} - {response.message}\")\n",
    "\n",
    "# 定义格式\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"菜品\",description=\"菜的名字\"),\n",
    "    ResponseSchema(name=\"地名\",description=\"该道菜品常见的地名\")\n",
    "]\n",
    "\n",
    "# 定义结构化输出解析器\n",
    "StrOutputParser = StructuredOutputParser.from_response_schemas(response_schemas=response_schemas)\n",
    "\n",
    "format_instructions = StrOutputParser.get_format_instructions()\n",
    "\n",
    "print(f\"结构化输出解析器的提示词:\\n {format_instructions}\")\n",
    "\n",
    "\n",
    "prompt = \"\"\"\n",
    "    根据用户的输入，提取所有的菜品和地名\\n\n",
    "    {format_instructions}{user_prompt}\n",
    "\"\"\"\n",
    "\n",
    "promptTemplate = PromptTemplate(\n",
    "    template = prompt,\n",
    "    input_variables = [\"user_prompt\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "\n",
    "query = promptTemplate.format_prompt(\n",
    "    user_prompt = \"\"\"\n",
    "日记：探索美食与地名的奇妙之旅\n",
    "日期：2025年4月9日\n",
    "今天，我踏上了一段令人兴奋的美食之旅，探索了几个独特的地名及其特色美食。\n",
    "早晨：杭州\n",
    "清晨，我来到了美丽的杭州。这里的西湖美景令人陶醉，湖边的早茶更是不可错过。我点了一份龙井虾仁，鲜嫩的虾仁搭配着清香的龙井茶，味道鲜美，令人回味无穷。\n",
    "中午：成都\n",
    "午餐时，我飞往了成都，享受了正宗的四川火锅。火锅的麻辣味道让我感受到了一种前所未有的刺激，搭配新鲜的蔬菜和肉类，每一口都充满了满足感。成都的街头小吃也让我流连忘返，尤其是兔头，香辣可口，令人欲罢不能。\n",
    "下午：广州\n",
    "下午，我来到了广州，享受了一顿地道的早茶。点心如虾饺、烧卖、和蛋挞，每一样都精致可口。我特别喜欢那一口咬下去，皮薄馅嫩的虾饺，仿佛整个早晨的疲惫都被一扫而空。\n",
    "晚上：上海\n",
    "晚上，我抵达了上海，漫步在繁华的南京路。这里的美食琳琅满目，我选择了生煎包作为晚餐。外皮酥脆，内馅多汁，搭配醋和姜丝，味道绝妙。\n",
    "总结\n",
    "这一天的旅程让我更加热爱中国的美食文化。每一个地方都有其独特的风味和故事，真是一次难忘的体验！期待下一次的美食探索之旅。\n",
    "\"\"\")\n",
    "print(f\"最终的提示词：\\n {query}\")\n",
    "print(\"=========结果===========\")\n",
    "response = chat_with_qwen(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自定义大模型解析器\n",
    "在某些情况下,您可能希望实现自定义解析器以将模型输出构购造为自定义格式\n",
    "有两种方法可以实现自定义解析器:\n",
    "- 在LCEL中使用RunnableLambda或RunnableGenerator-我门强烈建议大多数用例使用此方法\n",
    "- 通过从基类之一继承进行解析--这是困难方法\n",
    "这两种方法之间的差异大多是表面的,主要在于触发哪些回调(例如,on_chain_start 与 on_parser_start)\n",
    "## 可运行的Lambda和生成器\n",
    "推荐的解析方法是使用可运行的lambda和可运行的生成器!\n",
    "\n",
    "**下面是一段示例代码：用RunnableGenerator封装一个自定义的解析器用于流式输出**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在一个遥远的山谷里，有一片神秘的森林，人们称它为“星语林”。传说，在这片森林的深处，住着一位会说话的白鹿。白鹿拥有治愈人心的力量，但它只会在月圆之夜现身，并且只会帮助那些真正需要帮助的人。\n",
      "\n",
      "有一天，一个名叫小岚的女孩误入了星语林。她是一个孤儿，从小被村里的老人抚养长大。虽然生活清贫，但她总是心怀善意，喜欢帮助别人。然而，最近一场突如其来的洪水摧毁了她的家，也让她失去了唯一赖以生存的小木屋。无处可去的小岚只能漫无目的地走进了森林，希望能找到一些食物或者庇护所。\n",
      "\n",
      "夜幕降临，月亮渐渐升起，银白色的光芒洒满了整个森林。就在小岚感到绝望时，一只通体雪白、双角闪烁着微光的鹿缓缓出现在她面前。它的目光温柔而深邃，仿佛能看透人的内心。\n",
      "\n",
      "“你为何来到这里？”白鹿用低沉却清晰的声音问道。\n",
      "\n",
      "小岚惊讶得说不出话来，但还是鼓起勇气回答：“我……我的家被洪水冲毁了，我没有地方可以回去。”\n",
      "\n",
      "白鹿凝视着她良久，然后轻轻点了点头。“你的善良和坚韧打动了我。我愿意帮你实现一个愿望，但你要记住，这个愿望必须是真正对你和他人有益的。”\n",
      "\n",
      "小岚愣住了，她从未想过自己还能得到这样的机会。她低头思索片刻，然后抬起头坚定地说：“我希望我的家乡能够恢复生机，让所有失去家园的人都能重新开始新的生活。”\n",
      "\n",
      "白鹿听后露出了欣慰的笑容，它低下头用蹄子轻触地面，顿时一道柔和的光芒从脚下扩散开来。光芒笼罩了整片森林，随后化作一阵温暖的春风，吹向远方。\n",
      "\n",
      "第二天清晨，当第一缕阳光照进山谷时，小岚发现四周的一切都焕然一新。河流恢复了清澈，树木重新长出嫩绿的新芽，甚至还有几只小鸟在枝头欢快地歌唱。而更令人惊喜的是，她看到远处的村庄也已重建完毕，村民们正在忙碌地修缮房屋。\n",
      "\n",
      "从此以后，小岚不仅成为了村子的英雄，还用自己的双手帮助更多需要帮助的人。而关于星语林和白鹿的故事，则一直流传在人们的口耳之间，成为了一个关于希望与善良的美丽传说。"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Iterable\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import AIMessageChunk\n",
    "from langchain_core.runnables import RunnableGenerator\n",
    "\n",
    "# 定义一个LLM\n",
    "llm_streaming = ChatOpenAI(\n",
    "    model= \"qwen-turbo\",\n",
    "    api_key=os.getenv(\"API_KEY\"),\n",
    "    base_url=os.getenv(\"API_BASEURL\")\n",
    ")\n",
    "\n",
    "def streaming_parse(chunks: Iterable[AIMessageChunk]) -> Iterable[str]:\n",
    "    for chunk in chunks:\n",
    "        content = chunk.content\n",
    "        yield content\n",
    "\n",
    "streaming_output = RunnableGenerator(streaming_parse)\n",
    "\n",
    "chain = llm_streaming | streaming_output\n",
    "\n",
    "for chunk in chain.stream(\"讲一个故事\"):\n",
    "    print(chunk,end=\"\",flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Anaconda)",
   "language": "python",
   "name": "anaconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
